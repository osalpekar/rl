name: Tests on Linux GPU (Stable)

on:
  pull_request:
  push:
    branches:
      - nightly
      - main
      - release/*
  workflow_dispatch:

jobs:
  unittests:
    uses: pytorch/test-infra/.github/workflows/linux_job.yml@main
    with:
      repository: pytorch/rl
      runner: "linux.g5.4xlarge.nvidia.gpu"
      docker-image: "pytorch/manylinux-cuda116"
      run-with-docker: false
      timeout: 120
      script: |
        set -euxo pipefail

        export PYTHON_VERSION="3.9"
        export CU_VERSION="11.6"
        export TAR_OPTIONS="--no-same-owner"
        export UPLOAD_CHANNEL="nightly"
        export docker_image="pytorch/manylinux-cuda116"

        nvidia-smi

        docker run -e PYTHON_VERSION -e UPLOAD_CHANNEL -e CU_VERSION -t --gpus all -v $PWD:$PWD -w $PWD pytorch/manylinux-cuda116 .circleci/unittest/linux_stable/scripts/run_all.sh

        # docker run -e PYTHON_VERSION -t --gpus all -v $PWD:$PWD -w $PWD pytorch/manylinux-cuda116 .circleci/unittest/linux_stable/scripts/setup_env.sh
        # docker run -t --gpus all -v $PWD:$PWD -w $PWD -e UPLOAD_CHANNEL -e CU_VERSION pytorch/manylinux-cuda116 .circleci/unittest/linux_stable/scripts/install.sh
        # bash .circleci/unittest/linux_stable/scripts/run_test.sh
        # docker run -t --gpus all -v $PWD:$PWD -w $PWD pytorch/manylinux-cuda116 .circleci/unittest/linux_stable/scripts/post_process.sh
